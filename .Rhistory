data1.test = data.1[-train1,]#
data2.test = data.2[-train2,]#
test = rbind(data1.test,data2.test)#
#
y = c(rep(1,140),rep(2,140))#
#
### train an SVM on the data and use to predict new obs#
#
fit = glm(factor(y)~., data = as.data.frame(train), family = binomial)#
#
pred = as.numeric(predict(fit, as.data.frame(test), type="response"))#
pred[pred>.5] <- 2#
pred[pred<.5] <- 1#
true = c(rep(1,60),rep(2,60))#
error = mean((pred-true)!=0)#
#
return(error)}#
mean(replicate(1000,do.svm(1)))#
mean(replicate(1000,do.log()))
mean(replicate(1000,do.svm()))
library(e1071)#
#
do.svm = function(){#
#
### generate random data#
#
x1 = rnorm(200,0,1.5)#
y1 = rnorm(200,0,1.5)#
x2 = rnorm(200,2,1.5)#
y2 = rnorm(200,2,1.5)#
#
data.1 = cbind(x1,y1)#
data.2 = cbind(x2,y2)#
#
### plot(x1,y1,pch=20,col="blue",xlim=c(-3,5),ylim=c(-3,5))#
### points(x2,y2,pch=20,col="red")#
#
### designate 70% of points as training set#
#
train1 = sample(1:200,140,replace=FALSE)#
train2 = sample(1:200,140,replace=FALSE)#
#
data1.train = data.1[train1,]#
data2.train = data.2[train2,]#
train = rbind(data1.train,data2.train)#
#
data1.test = data.1[-train1,]#
data2.test = data.2[-train2,]#
test = rbind(data1.test,data2.test)#
#
y = c(rep(1,140),rep(2,140))#
#
### train an SVM on the data and use to predict new obs#
#
fit = svm(factor(y)~., data = train, scale=FALSE, kernel = "radial")#
pred = as.numeric(predict(fit, test))#
#
true = c(rep(1,60),rep(2,60))#
error = mean((pred-true)!=0)#
#
return(error)}#
#########################################################
### compare predictive power vs. logistic regression ####
#########################################################
do.log = function(){#
#
### generate random data#
#
x1 = rnorm(200,0,1.5)#
y1 = rnorm(200,0,1.5)#
x2 = rnorm(200,2,1.5)#
y2 = rnorm(200,2,1.5)#
#
data.1 = cbind(x1,y1)#
data.2 = cbind(x2,y2)#
#
### plot(x1,y1,pch=20,col="blue",xlim=c(-3,5),ylim=c(-3,5))#
### points(x2,y2,pch=20,col="red")#
#
### designate 70% of points as training set#
#
train1 = sample(1:200,140,replace=FALSE)#
train2 = sample(1:200,140,replace=FALSE)#
#
data1.train = data.1[train1,]#
data2.train = data.2[train2,]#
train = rbind(data1.train,data2.train)#
#
data1.test = data.1[-train1,]#
data2.test = data.2[-train2,]#
test = rbind(data1.test,data2.test)#
#
y = c(rep(1,140),rep(2,140))#
#
### train an SVM on the data and use to predict new obs#
#
fit = glm(factor(y)~., data = as.data.frame(train), family = binomial)#
#
pred = as.numeric(predict(fit, as.data.frame(test), type="response"))#
pred[pred>.5] <- 2#
pred[pred<.5] <- 1#
true = c(rep(1,60),rep(2,60))#
error = mean((pred-true)!=0)#
#
return(error)}#
mean(replicate(1000,do.svm()))#
mean(replicate(1000,do.log()))
x1 = rnorm(200,0,.5)#
y1 = rnorm(200,0,.5)#
x2 = rnorm(200,0,1.5)#
y2 = rnorm(200,0,1.5)#
#
data.1 = cbind(x1,y1)#
data.2 = cbind(x2,y2)#
#
plot(x1,y1,pch=20,col="blue",xlim=c(-3,5),ylim=c(-3,5))#
points(x2,y2,pch=20,col="red")
library(e1071)#
#
do.svm = function(){#
#
### generate random data#
#
x1 = rnorm(200,0,.5)#
y1 = rnorm(200,0,.5)#
x2 = rnorm(200,0,1.5)#
y2 = rnorm(200,0,1.5)#
#
data.1 = cbind(x1,y1)#
data.2 = cbind(x2,y2)#
#
plot(x1,y1,pch=20,col="blue",xlim=c(-3,5),ylim=c(-3,5))#
points(x2,y2,pch=20,col="red")#
#
### designate 70% of points as training set#
#
train1 = sample(1:200,140,replace=FALSE)#
train2 = sample(1:200,140,replace=FALSE)#
#
data1.train = data.1[train1,]#
data2.train = data.2[train2,]#
train = rbind(data1.train,data2.train)#
#
data1.test = data.1[-train1,]#
data2.test = data.2[-train2,]#
test = rbind(data1.test,data2.test)#
#
y = c(rep(1,140),rep(2,140))#
#
### train an SVM on the data and use to predict new obs#
#
fit = svm(factor(y)~., data = train, scale=FALSE, kernel = "radial")#
pred = as.numeric(predict(fit, test))#
#
true = c(rep(1,60),rep(2,60))#
error = mean((pred-true)!=0)#
#
return(error)}#
#########################################################
### compare predictive power vs. logistic regression ####
#########################################################
do.log = function(){#
#
### generate random data#
#
x1 = rnorm(200,0,.5)#
y1 = rnorm(200,0,.5)#
x2 = rnorm(200,0,1.5)#
y2 = rnorm(200,0,1.5)#
#
data.1 = cbind(x1,y1)#
data.2 = cbind(x2,y2)#
#
### plot(x1,y1,pch=20,col="blue",xlim=c(-3,5),ylim=c(-3,5))#
### points(x2,y2,pch=20,col="red")#
#
### designate 70% of points as training set#
#
train1 = sample(1:200,140,replace=FALSE)#
train2 = sample(1:200,140,replace=FALSE)#
#
data1.train = data.1[train1,]#
data2.train = data.2[train2,]#
train = rbind(data1.train,data2.train)#
#
data1.test = data.1[-train1,]#
data2.test = data.2[-train2,]#
test = rbind(data1.test,data2.test)#
#
y = c(rep(1,140),rep(2,140))#
#
### train an SVM on the data and use to predict new obs#
#
fit = glm(factor(y)~., data = as.data.frame(train), family = binomial)#
#
pred = as.numeric(predict(fit, as.data.frame(test), type="response"))#
pred[pred>.5] <- 2#
pred[pred<.5] <- 1#
true = c(rep(1,60),rep(2,60))#
error = mean((pred-true)!=0)#
#
return(error)}#
mean(replicate(1000,do.svm()))#
mean(replicate(1000,do.log()))
library(e1071)#
#
do.svm = function(){#
#
### generate random data#
#
x1 = rnorm(200,0,.5)#
y1 = rnorm(200,0,.5)#
x2 = rnorm(200,0,1.5)#
y2 = rnorm(200,0,1.5)#
#
data.1 = cbind(x1,y1)#
data.2 = cbind(x2,y2)#
#
#plot(x1,y1,pch=20,col="blue",xlim=c(-3,5),ylim=c(-3,5))#
#points(x2,y2,pch=20,col="red")#
#
### designate 70% of points as training set#
#
train1 = sample(1:200,140,replace=FALSE)#
train2 = sample(1:200,140,replace=FALSE)#
#
data1.train = data.1[train1,]#
data2.train = data.2[train2,]#
train = rbind(data1.train,data2.train)#
#
data1.test = data.1[-train1,]#
data2.test = data.2[-train2,]#
test = rbind(data1.test,data2.test)#
#
y = c(rep(1,140),rep(2,140))#
#
### train an SVM on the data and use to predict new obs#
#
fit = svm(factor(y)~., data = train, scale=FALSE, kernel = "radial")#
pred = as.numeric(predict(fit, test))#
#
true = c(rep(1,60),rep(2,60))#
error = mean((pred-true)!=0)#
#
return(error)}#
#########################################################
### compare predictive power vs. logistic regression ####
#########################################################
do.log = function(){#
#
### generate random data#
#
x1 = rnorm(200,0,.5)#
y1 = rnorm(200,0,.5)#
x2 = rnorm(200,0,1.5)#
y2 = rnorm(200,0,1.5)#
#
data.1 = cbind(x1,y1)#
data.2 = cbind(x2,y2)#
#
### plot(x1,y1,pch=20,col="blue",xlim=c(-3,5),ylim=c(-3,5))#
### points(x2,y2,pch=20,col="red")#
#
### designate 70% of points as training set#
#
train1 = sample(1:200,140,replace=FALSE)#
train2 = sample(1:200,140,replace=FALSE)#
#
data1.train = data.1[train1,]#
data2.train = data.2[train2,]#
train = rbind(data1.train,data2.train)#
#
data1.test = data.1[-train1,]#
data2.test = data.2[-train2,]#
test = rbind(data1.test,data2.test)#
#
y = c(rep(1,140),rep(2,140))#
#
### train an SVM on the data and use to predict new obs#
#
fit = glm(factor(y)~., data = as.data.frame(train), family = binomial)#
#
pred = as.numeric(predict(fit, as.data.frame(test), type="response"))#
pred[pred>.5] <- 2#
pred[pred<.5] <- 1#
true = c(rep(1,60),rep(2,60))#
error = mean((pred-true)!=0)#
#
return(error)}#
mean(replicate(1000,do.svm()))#
mean(replicate(1000,do.log()))
-.2*log(1/2)
.2*log(2)
search()
help(package="datasets")
airquality
x<-matrix(c(1,2,3,4),2)
x
rowMeans(z)
rowMeans(x)
columnMeans(x)
colMeans(x)
rowSum(x)
sumRows(x)
rowSums(x)
rnorm(2*2)
gl(1,2)
x<-c1:4
x<-1:4
range(x)
cube<-function(x,n) {x^3}
cube(3)
x<-1:10
if(x>5)
x<-x+1
c<-c
if(x>5)c<-c+1
x<-1:10
if(x>5){x<-0}
?if
help(if)
f <- function(x) {#
        g <- function(y) {#
                y + z#
        }#
        z <- 4#
        x + g(x)#
}
z<-10
f(30)
f(3)
x <- 5#
y <- if(x < 3) {#
        NA#
} else {#
        10#
}
y
data(iris)
iris
?iris
attach(iris)
names(iris)
table(Species)
split(iris,Species)
x<-split(iris,Species)
sapply(x$virginica,mean)
sapply(x$virginica[,1],mean)
mean(x$virginica[,1])
mean(iris[,1][Species=="virginica"])
apply(iris[,1:4],1,mean)
apply(iris[,1:4],2,mean)
mean(iris[,1])
mean(iris[,2])
mean(iris[,2)
data(mtcars)
names(mtcars)
attach(mtcars)
table(cyl)
sapply(mtcars,cyl,mean)
tapply(mtcars$cyl, mtcars$mpg, mean)
tapply(mtcars$mpg, mtcars$cyl, mean)
tapply(Sepal.Length,Species,mean)
tapply(mtcars$hp,mtcars$cyl,mean)
z<-tapply(mtcars$hp,mtcars$cyl,mean)
z[3]-z[1]
debug(ls)
ls()
quit()
s
log(.64)/100
log(.64^(-0.1))
log(.64^(-0.01))
exp(-50*log(.64^(-.01)))
z<-matrix()
z
makeCacheMatrix <- function(x = matrix()) {#
        inv <- NULL#
        set <- function(y) {#
                x <<- y#
                inv <<- NULL#
        }#
        get <- function() x#
        setinv <- function(inverse) inv <<- inverse#
        getinv <- function() inv#
        list(set = set, get = get,#
             setinv = setinv,#
             getinv = getinv)#
}
w<-matrix(c(1,2,3,4),3)
w<-matrix(c(1,2,3,4),2)
w
z<makeCacheMatrix()
z<makeCacheMatrix(w)
makeCacheMatrix <- function(x) {#
        inv <- NULL#
        set <- function(y) {#
                x <<- y#
                inv <<- NULL#
        }#
        get <- function() x#
        setinv <- function(inverse) inv <<- inverse#
        getinv <- function() inv#
        list(set = set, get = get,#
             setinv = setinv,#
             getinv = getinv)#
}
w
z<-makeCacheMatrix(w)
z
z$get()
cachesolve <- function(x, ...) {#
        inv <- x$getinv()#
        if(!is.null(inv)) {#
                message("getting cached data")#
                return(inv)#
        }#
        data <- x$get()#
        inv <- solve(data, ...)#
        x$setinv(inv)#
        inv#
}
cachesolve(w)
w
z
cachesolve(z)
w<-matrix(c(rnorm(100,0,1)),10)
w
cachesolve(w)
cachesolve(makeCacheMatrix(w))
w
z<-makeCacheMatrix(w)
cahceSolve(z)
cacheSolve(z)
cacheSolve <- function(x, ...) {#
        inv <- x$getinv()#
        if(!is.null(inv)) {#
                message("getting cached data")#
                return(inv)#
        }#
        data <- x$get()#
        inv <- solve(data, ...)#
        x$setinv(inv)#
        inv#
}
cacheSolve(z)
w<-matrix(c(rnorm(2500,0,1)),50)
z<-makeCacheMatrix(w)
cacheSolve(z)
n<-200#
w<-matrix(c(rnorm(n^2,0,1)),n)#
z<-makeCacheMatrix(w)#
cacheSolve(z)
cacheSolve(z)
system.time(cacheSolve(z))
n<-300#
w<-matrix(c(rnorm(n^2,0,1)),n)#
z<-makeCacheMatrix(w)#
system.time(cache.Solve(z))#
system.time(cache.Solve(z))
n<-300#
w<-matrix(c(rnorm(n^2,0,1)),n)#
z<-makeCacheMatrix(w)#
system.time(cacheSolve(z))#
system.time(cacheSolve(z))
n<-400#
w<-matrix(c(rnorm(n^2,0,1)),n)#
z<-makeCacheMatrix(w)#
system.time(cacheSolve(z))#
system.time(cacheSolve(z))
n<-1000#
w<-matrix(c(rnorm(n^2,0,1)),n)#
z<-makeCacheMatrix(w)#
system.time(cacheSolve(z))#
system.time(cacheSolve(z))
n<-10#
w<-matrix(rnorm(n^2,0,1),n)#
z<-makeCacheMatrix(w)#
system.time(cacheSolve(z))
n<-100#
w<-matrix(rnorm(n^2,0,1),n)#
z<-makeCacheMatrix(w)#
system.time(cacheSolve(z))#
system.time(cacheSolve(z))
n<-500#
w<-matrix(rnorm(n^2,0,1),n)#
z<-makeCacheMatrix(w)#
system.time(cacheSolve(z))#
system.time(cacheSolve(z))
n<-800#
w<-matrix(rnorm(n^2,0,1),n)#
z<-makeCacheMatrix(w)#
system.time(cacheSolve(z))#
system.time(cacheSolve(z))
x<-data.frame(y=c(1,2),z=c(3,4))
x
names(x)<-c("billy","sam")
x
mean(x[,1])
mean(x[,2])
mean(x)
mean(as.vector(x))
x
is.numeric(x)
mean(as.numeric9x)
mean(as.numeric(x))
6.75*80
40*50
2000*50
.01*30000
40*2000
558+73+533
### load in the data #
#
train <- read.table("X_train.txt")#
test <- read.table("X_test.txt")#
train.subj <- read.table("subject_train.txt")#
test.subj <- read.table("subject_test.txt")#
features <- read.table("features.txt")#
y.train <- read.table("y_train.txt")#
y.test <- read.table("y_test.txt")#
#
### merge into one dataset#
#
feat.text<-as.character(features[,2])#
y.train <- unlist(y.train)#
y.test <- unlist(y.test)#
y <- c(y.train,y.test)#
train.subj <- unlist(train.subj)#
test.subj <- unlist(test.subj)#
subj <- c(train.subj,test.subj)#
data <- rbind(train,test)#
#
### extract only those features pertaining to the mean #
### or standard deviation of a measurement#
#
mean.in.name <- regexpr('mean\\(\\)',feat.text)#
std.in.name <- regexpr('std\\(\\)',feat.text)#
feat.new <- c(which(mean.in.name>-1),	#
	which(std.in.name>-1))#
data <- data[,feat.new]#
#
### assign descriptive names to the variables#
### 1 -> walking#
### 2 -> walking_upstairs#
### 3 -> walking_downstairs#
### 4 -> sitting#
### 5 -> standing#
### 6 -> laying#
#
act.labels <- c('walking','walking_upstairs','walking_downstairs',#
	'sitting','standing','laying')#
activity <- factor(y,labels = act.labels)#
data <- cbind(data,subj,activity)#
desc_vars <- c(feat.text[feat.new],'subject','activity')#
names(data) <- desc_vars#
attach(data)#
#
### create independent, tidy data set#
### with average of each variable for each activity#
### and each subject#
#
aggdata <- aggregate(data[,1:(ncol(data)-2)], by=list(subj,activity),#
	FUN=mean,na.rm=TRUE)#
tidydata <- aggdata#
names(tidydata)[1]<-'Subject'#
names(tidydata)[2]<-'Activity'#
write.table(tidydata,file='tidydata.txt',row.name=FALSE)
getwd()
setwd('./Desktop/project')
### load in the data #
#
train <- read.table("X_train.txt")#
test <- read.table("X_test.txt")#
train.subj <- read.table("subject_train.txt")#
test.subj <- read.table("subject_test.txt")#
features <- read.table("features.txt")#
y.train <- read.table("y_train.txt")#
y.test <- read.table("y_test.txt")#
#
### merge into one dataset#
#
feat.text<-as.character(features[,2])#
y.train <- unlist(y.train)#
y.test <- unlist(y.test)#
y <- c(y.train,y.test)#
train.subj <- unlist(train.subj)#
test.subj <- unlist(test.subj)#
subj <- c(train.subj,test.subj)#
data <- rbind(train,test)#
#
### extract only those features pertaining to the mean #
### or standard deviation of a measurement#
#
mean.in.name <- regexpr('mean\\(\\)',feat.text)#
std.in.name <- regexpr('std\\(\\)',feat.text)#
feat.new <- c(which(mean.in.name>-1),	#
	which(std.in.name>-1))#
data <- data[,feat.new]#
#
### assign descriptive names to the variables#
### 1 -> walking#
### 2 -> walking_upstairs#
### 3 -> walking_downstairs#
### 4 -> sitting#
### 5 -> standing#
### 6 -> laying#
#
act.labels <- c('walking','walking_upstairs','walking_downstairs',#
	'sitting','standing','laying')#
activity <- factor(y,labels = act.labels)#
data <- cbind(data,subj,activity)#
desc_vars <- c(feat.text[feat.new],'subject','activity')#
names(data) <- desc_vars#
attach(data)#
#
### create independent, tidy data set#
### with average of each variable for each activity#
### and each subject#
#
aggdata <- aggregate(data[,1:(ncol(data)-2)], by=list(subj,activity),#
	FUN=mean,na.rm=TRUE)#
tidydata <- aggdata#
names(tidydata)[1]<-'Subject'#
names(tidydata)[2]<-'Activity'#
write.table(tidydata,file='tidydata.txt',row.name=FALSE)
head(tidydata)
